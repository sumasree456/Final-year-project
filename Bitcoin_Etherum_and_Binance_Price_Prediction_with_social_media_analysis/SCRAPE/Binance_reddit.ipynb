{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601e0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b642c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pushshift_data(query, after, before, sub):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?title=' + str(query) + '&size=1000&after=' + str(\n",
    "        after) + '&before=' + str(before) + '&subreddit=' + str(sub)\n",
    "\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e1aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sub_data(subm):\n",
    "    sub_data = list()  # list to store data points\n",
    "    title = subm['title']\n",
    "    url = subm['url']\n",
    "    try:\n",
    "        # if flair is available then get it, else set 'NaN'\n",
    "        flair = subm['link_flair_text']\n",
    "    except KeyError:\n",
    "        flair = 'NaN'\n",
    "    author = subm['author']\n",
    "    sub_id = subm['id']\n",
    "    score = subm['score']\n",
    "    try:\n",
    "        # if selftext is available then get it, else set it empty\n",
    "        selftext = subm['selftext']\n",
    "        list_of_empty_markers = ['[removed]', '[deleted]']\n",
    "        # many times selftext would be removed or deleted, if thats the case then set it empty\n",
    "        if selftext in list_of_empty_markers:\n",
    "            selftext = ''\n",
    "    except:\n",
    "        selftext = ''\n",
    "    created = datetime.datetime.fromtimestamp(subm['created_utc'])  # 1520561700.0\n",
    "    numComms = subm['num_comments']\n",
    "    permalink = subm['permalink']\n",
    "\n",
    "    sub_data.append((sub_id, title, selftext, url, author, score, created, numComms, permalink, flair))\n",
    "    sub_stats[sub_id] = sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ffd85d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_subs_to_file(filename):\n",
    "    upload_count = 0\n",
    "    if os.path.exists(filename):\n",
    "        keep_header = False\n",
    "    else:\n",
    "        keep_header = True\n",
    "\n",
    "    with open(filename, 'a',encoding='utf-8', newline='') as file:\n",
    "        a = csv.writer(file, delimiter=',')\n",
    "        headers = ['post_id', 'title', 'selftext', 'url', 'author', 'score', 'publish_date', 'num_of_comments',\n",
    "                   'permalink', 'flair']\n",
    "        if keep_header:\n",
    "            a.writerow(headers)\n",
    "        for sub in sub_stats:\n",
    "            a.writerow(sub_stats[sub][0])\n",
    "            upload_count += 1\n",
    "        # print(str(upload_count) + ' submissions have been uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    sub_reddit = 'Binance'\n",
    "    key_word = 'Binance'\n",
    "    output_filename = 'Reddit_data_Binance__.csv'\n",
    "    start_date = datetime.datetime(2022, 1, 1, 0)\n",
    "    end_date = datetime.datetime(2022, 3, 31, 0)\n",
    "    one_day = datetime.timedelta(hours=24)\n",
    "    after_date = start_date\n",
    "    after = str(int(after_date.timestamp()))\n",
    "    before_date = start_date + one_day\n",
    "    before = str(int(before_date.timestamp()))\n",
    "\n",
    "    while after_date < end_date:\n",
    "        sub_count = 0\n",
    "        sub_stats = {}\n",
    "        data = get_pushshift_data(key_word, after, before, sub_reddit)\n",
    "        max_count = 100\n",
    "        count = 0\n",
    "        while len(data) > 0 and count < max_count:\n",
    "            for submission in data:\n",
    "                collect_sub_data(submission)\n",
    "                sub_count += 1\n",
    "            print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
    "            after = data[-1]['created_utc']\n",
    "            data = get_pushshift_data(key_word, after, before, sub_reddit)\n",
    "            count = count + 1\n",
    "        write_subs_to_file(output_filename)\n",
    "        after_date += one_day\n",
    "        after = str(int(after_date.timestamp()))\n",
    "        before_date += one_day\n",
    "        before = str(int(before_date.timestamp()))\n",
    "        time.sleep(np.random.randint(1, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
